{
    "os": "Linux-5.4.0-90-generic-x86_64-with-glibc2.27",
    "python": "3.9.7",
    "heartbeatAt": "2022-02-10T10:32:54.624681",
    "startedAt": "2022-02-10T10:32:53.368164",
    "docker": null,
    "gpu": "GeForce RTX 3090",
    "gpu_count": 1,
    "cpu_count": 36,
    "cuda": null,
    "args": [
        "--model_name_or_path=cl-tohoku/bert-base-japanese-whole-word-masking",
        "--do_train",
        "--do_eval",
        "--max_seq_length=128",
        "--per_device_train_batch_size=32",
        "--use_fast_tokenizer",
        "--learning_rate=2e-5",
        "--num_train_epochs=30",
        "--output_dir=../output/multitasking-bert-base-japanese-whole-word-masking-data/",
        "--train_file_task1=../data/negaposi/train.csv",
        "--train_file_task2=../data/category/train.csv",
        "--validation_file_task1=../data/negaposi/valid.csv",
        "--validation_file_task2=../data/category/valid.csv",
        "--run_name",
        "multitasking-bert-base-japanese-whole-word-masking-data",
        "--logging_dir",
        "../logs/multitasking-bert-base-japanese-whole-word-masking-data/",
        "--logging_strategy",
        "steps",
        "--logging_steps",
        "50",
        "--evaluation_strategy",
        "steps",
        "--load_best_model_at_end",
        "--eval_steps",
        "50",
        "--metric_for_best_model",
        "eval_loss"
    ],
    "state": "running",
    "program": "/home/kinouchitakahiro/Documents/saya_res_maltitasking/src/./run_glue_edit.py",
    "codePath": "run_glue_edit.py",
    "host": "kinouchi-ubuntu",
    "username": "kinouchitakahiro",
    "executable": "/home/kinouchitakahiro/anaconda3/envs/saya_clustering/bin/python"
}
