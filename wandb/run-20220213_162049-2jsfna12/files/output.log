Skipping the first batches:  31%|███████████████████▌                                            | 210/686 [00:07<00:03, 132.32it/s]
  0%|                                                                                                      | 0/2721 [00:00<?, ?it/s]












100%|██████████████████████████████████████████████████████████████████████████████████████████▊| 2716/2721 [00:37<00:00,  6.70it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████▉| 2720/2721 [00:38<00:00,  6.45it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
[INFO|trainer.py:1489] 2022-02-13 16:21:34,225 >> Loading best model from __output/checkpoint-1500 (score: 0.7093577980995178).
100%|███████████████████████████████████████████████████████████████████████████████████████████| 2721/2721 [00:38<00:00, 69.94it/s]
[INFO|trainer.py:2103] 2022-02-13 16:21:34,463 >> Saving model checkpoint to __output███████████| 2721/2721 [00:38<00:00,  6.45it/s]
[INFO|trainer.py:2112] 2022-02-13 16:21:34,464 >> Trainer.model is not a `PreTrainedModel`, only saving its state dict.
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     0.0638
  train_runtime            = 0:00:45.07
  train_samples            =      29009
  train_samples_per_second =   1930.722
  train_steps_per_second   =     60.366
02/13/2022 16:21:35 - INFO - __main__ - *** Evaluate of negaposi ***
[INFO|tokenization_utils_base.py:2074] 2022-02-13 16:21:35,791 >> tokenizer config file saved in __output/tokenizer_config.json
[INFO|tokenization_utils_base.py:2080] 2022-02-13 16:21:35,791 >> Special tokens file saved in __output/special_tokens_map.json
[INFO|tokenization_t5_fast.py:162] 2022-02-13 16:21:35,838 >> Copy vocab file to __output/spiece.model
[INFO|trainer.py:553] 2022-02-13 16:21:35,848 >> The following columns in the evaluation set  don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: sentence.
[INFO|trainer.py:2353] 2022-02-13 16:21:35,851 >> ***** Running Evaluation *****
[INFO|trainer.py:2355] 2022-02-13 16:21:35,851 >>   Num examples = 7114
[INFO|trainer.py:2358] 2022-02-13 16:21:35,851 >>   Batch size = 8





100%|█████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [00:13<00:00, 65.09it/s]
[INFO|trainer.py:553] 2022-02-13 16:21:49,546 >> The following columns in the evaluation set  don't have a corresponding argument in `MultiTaskModel.forward` and have been ignored: sentence.
[INFO|trainer.py:2353] 2022-02-13 16:21:49,548 >> ***** Running Evaluation *****
[INFO|trainer.py:2355] 2022-02-13 16:21:49,548 >>   Num examples = 6395
[INFO|trainer.py:2358] 2022-02-13 16:21:49,548 >>   Batch size = 8
  0%|                                                                                                       | 0/800 [00:00<?, ?it/s]
***** eval metrics *****
  epoch                   =        3.0
  eval_accuracy_task1     =          0
  eval_accuracy_task2     =     0.7776
  eval_loss               =     0.5411
  eval_runtime            = 0:00:13.68
  eval_samples            =       7114
  eval_samples_per_second =    519.725
  eval_steps_per_second   =      65.02






 96%|█████████████████████████████████████████████████████████████████████████████████████████    | 766/800 [00:11<00:00, 66.41it/s]
***** eval metrics *****
  epoch                   =        3.0
  eval_accuracy_task1     =     0.6711
  eval_accuracy_task2     =          0
  eval_loss               =     0.8959
  eval_runtime            = 0:00:12.44
  eval_samples            =       6395
  eval_samples_per_second =    514.032
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:12<00:00, 64.38it/s]
[INFO|modelcard.py:460] 2022-02-13 16:22:03,267 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Text Classification', 'type': 'text-classification'}}